{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bccce0ee",
      "metadata": {
        "id": "bccce0ee"
      },
      "source": [
        "# Pipeline for fetch 4 stars reviews\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions"
      ],
      "metadata": {
        "id": "pUeV8C-2mPkL"
      },
      "id": "pUeV8C-2mPkL"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5b42c00f",
      "metadata": {
        "id": "5b42c00f"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import snapshot_download, upload_file, HfApi\n",
        "import pathlib\n",
        "import time\n",
        "import json\n",
        "import logging\n",
        "import pandas as pd\n",
        "\n",
        "def download_reviews_data(category_idx:str):\n",
        "  logger = logging.getLogger(f'fetch reviews data for {category_idx} ')\n",
        "  logger.setLevel(logging.DEBUG)\n",
        "  try:\n",
        "    path_to_file = pathlib.Path(f\"/content/dataset/raw/review_categories/{category_idx}.jsonl\")\n",
        "    if not path_to_file.exists():\n",
        "      snapshot_download(repo_id=\"McAuley-Lab/Amazon-Reviews-2023\",\n",
        "                  local_dir=\"/content/dataset\",\n",
        "                  repo_type=\"dataset\",\n",
        "                  allow_patterns=[f\"raw/review_categories/{category_idx}.jsonl*\"])\n",
        "    logger.info(f\"Successfully downloaded reviews data for category {category_idx}\")\n",
        "  except Exception as e:\n",
        "    logger.error(f\"Failed to download reviews data for category {category_idx} - exception: {e}\")\n",
        "\n",
        "def download_items_data(category_idx:str):\n",
        "  logger = logging.getLogger(f'fetch items data for {category_idx} ')\n",
        "  logger.setLevel(logging.DEBUG)\n",
        "  try:\n",
        "    path_to_file = pathlib.Path(f\"/content/dataset/raw/meta_categories/meta_{category_idx}.jsonl\")\n",
        "    if not path_to_file.exists():\n",
        "      snapshot_download(repo_id=\"McAuley-Lab/Amazon-Reviews-2023\",\n",
        "                    local_dir=\"/content/dataset\",\n",
        "                    repo_type=\"dataset\",\n",
        "                    allow_patterns=[f\"raw/meta_categories/meta_{category_idx}.jsonl*\"])\n",
        "      logger.info(f\"Successfully downloaded items data for category {category_idx}\")\n",
        "  except:\n",
        "    print(f\"Failed to download items data for category {category_idx}\")\n",
        "\n",
        "def fetch_reviews_data(target_idxs,filepath_review_category):\n",
        "  filtered_reviews = []\n",
        "  logger = logging.getLogger(f'Filter 4 star reviews for {filepath_review_category} ')\n",
        "  logger.setLevel(logging.DEBUG)\n",
        "  count = 0\n",
        "  reviews_per_item_count = {}\n",
        "  with open(filepath_review_category, 'r') as file:\n",
        "    for line in file:\n",
        "        item = json.loads(line)\n",
        "        asin = item.get(\"parent_asin\")\n",
        "        rating = item.get(\"rating\")\n",
        "        text = item.get(\"text\", \"\")\n",
        "\n",
        "        ## Only search if is in target_idxs\n",
        "        if asin in target_idxs:\n",
        "          # Apply filters\n",
        "          if 4.0 <= rating <= 4.9 and len(text) > 100:\n",
        "              item_dict = {}\n",
        "              item_dict[\"ori_review\"] = text\n",
        "              item_dict[\"asin\"] = asin\n",
        "              item_dict[\"rating\"] = rating\n",
        "              if asin not in reviews_per_item_count:\n",
        "                reviews_per_item_count[asin] = 1\n",
        "                filtered_reviews.append(item_dict)\n",
        "                count += 1\n",
        "              else:\n",
        "                reviews_per_item_count[asin] += 1\n",
        "                if reviews_per_item_count[asin] < 4:\n",
        "                  filtered_reviews.append(item_dict)\n",
        "                  count += 1\n",
        "                  if count % 1000 == 0:\n",
        "                    logger.debug(f\"Processed {count} reviews\")\n",
        "\n",
        "    logger.info(f\"Successfully fetched {len(filtered_reviews)} reviews data for category {filepath_review_category}\")\n",
        "    return filtered_reviews\n",
        "\n",
        "def fetch_items_data(target_idxs,filepath_meta_category):\n",
        "  filtered_items_meta =  []\n",
        "  logger = logging.getLogger(f'fetch reviews data for {filepath_meta_category} ')\n",
        "  logger.setLevel(logging.DEBUG)\n",
        "  with open(filepath_meta_category, 'rb') as file:\n",
        "    for line in file:\n",
        "      line = json.loads(line)\n",
        "      curr_asin = line.get(\"parent_asin\")\n",
        "      if curr_asin in target_idxs:\n",
        "        meta_dict = {}\n",
        "        meta_dict[\"main_category\"] = line.get(\"main_category\")\n",
        "        meta_dict[\"title\"] = line.get(\"title\")\n",
        "        meta_dict[\"parent_asin\"] = line.get(\"parent_asin\")\n",
        "        meta_dict[\"description\"] = line.get(\"description\")\n",
        "        meta_dict[\"categories\"] = line.get(\"categories\")\n",
        "        meta_dict[\"features\"] = line.get(\"features\")\n",
        "        filtered_items_meta.append(meta_dict)\n",
        "  logger.info(f\"Successfully fetched {len(filtered_items_meta)} items data for category {filepath_meta_category}\")\n",
        "  return filtered_items_meta\n",
        "\n",
        "\n",
        "def build_final_dataframe(df_items,df_reviews,category_idx=None,save_parquet=False):\n",
        "  logger = logging.getLogger(f'build final dataframe for {category_idx} ')\n",
        "  logger.setLevel(logging.DEBUG)\n",
        "  df_final = df_reviews.join(df_items.set_index(\"parent_asin\")[\"title\"],on=[\"asin\"],how=\"left\")\n",
        "  if save_parquet and category_idx:\n",
        "    path = pathlib.Path(f\"/content/dataset/raw/review_and_meta_categories/filtered_4_star_reviews_{category_idx}.parquet\")\n",
        "    if not path.parent.exists():\n",
        "      path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    df_final.to_parquet(f\"/content/dataset/raw/review_and_meta_categories/filtered_4_star_reviews_{category_idx}.parquet\")\n",
        "    logger.info(f\"Save file in /content/dataset/raw/review_and_meta_categories/filtered_4_star_reviews_{category_idx}.parquet\")\n",
        "  return df_final\n",
        "\n",
        "def clear_reviews_data(category_idx:str):\n",
        "  logger = logging.getLogger(f'clear reviews data for {category_idx} ')\n",
        "  logger.setLevel(logging.DEBUG)\n",
        "  try:\n",
        "    path = pathlib.Path(f\"/content/dataset/raw/review_categories/{category_idx}.jsonl\")\n",
        "    path.unlink(missing_ok=True)\n",
        "    logger.info(f'Removed /content/dataset/raw/review_categories/{category_idx}.jsonl')\n",
        "  except:\n",
        "    logger.info(f'Could not remove /content/dataset/raw/review_categories/{category_idx}.jsonl')\n",
        "\n",
        "\n",
        "def clear_items_data(category_idx:str):\n",
        "  logger = logging.getLogger(f'clear items data for {category_idx} ')\n",
        "  logger.setLevel(logging.DEBUG)\n",
        "  try:\n",
        "    path = pathlib.Path(f\"raw/meta_categories/meta_{category_idx}.jsonl\")\n",
        "    path.unlink(missing_ok=True)\n",
        "    logger.info(f'Removed raw/meta_categories/meta_{category_idx}.jsonl')\n",
        "  except:\n",
        "    logger.info(f'Could not remove raw/meta_categories/meta_{category_idx}.jsonl')\n",
        "\n",
        "\n",
        "def pipeline_for_fetch_reviews(category_idx,target_idxs):\n",
        "  try:\n",
        "    logger = logging.getLogger(f'Pipeline for fetch reviews data from category {category_idx} ')\n",
        "    logger.setLevel(logging.DEBUG)\n",
        "    download_reviews_data(category_idx)\n",
        "    filepath_review_category = f'dataset/raw/review_categories/{category_idx}.jsonl'\n",
        "    filtered_reviews = fetch_reviews_data(target_idxs,filepath_review_category)\n",
        "    df_final = pd.DataFrame.from_records(filtered_reviews)\n",
        "    df_final.to_parquet(f'/content/dataset/raw/review_categories/filtered_4_star_reviews_{category_idx}.parquet')\n",
        "    logger.info(f\"Successfully saved filtered 4 star reviews in raw/review_categories/filtered_4_star_reviews_{category_idx}.parquet\")\n",
        "    clear_reviews_data(category_idx)\n",
        "  except Exception as e:\n",
        "    logger.error(f'Failed to pipeline for fetch reviews data from category {category_idx} == Exception: {e}')\n",
        "\n",
        "def pipeline_for_fetch_items(category_idx,target_idxs):\n",
        "  try:\n",
        "    logger = logging.getLogger(f'Pipeline for fetch items data ')\n",
        "    logger.setLevel(logging.DEBUG)\n",
        "    download_items_data(category_idx)\n",
        "    filepath_meta_category = f'dataset/raw/meta_categories/meta_{category_idx}.jsonl'\n",
        "    filtered_items_meta = fetch_items_data(target_idxs,filepath_meta_category)\n",
        "    df_final = pd.DataFrame.from_records(filtered_items_meta)\n",
        "    df_final.to_parquet(f'/content/dataset/raw/meta_categories/filtered_items_{category_idx}.parquet')\n",
        "    logger.info(f\"Successfully saved filtered items in dataset/raw/meta_categories/filtered_items_{category_idx}.parquet\")\n",
        "    clear_items_data(category_idx)\n",
        "  except Exception as e:\n",
        "    logger.error(f'Failed to pipeline for fetch items data == Exception: {e}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "08b0108f",
      "metadata": {
        "id": "08b0108f",
        "outputId": "8791cc02-65e9-4f45-db53-e78b3101522b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "select category_idx: Handmade Products\n"
          ]
        }
      ],
      "source": [
        "target_idxs = set()\n",
        "category_idxs = set()\n",
        "with open('/content/datasets/asin2categoryfiltered.json') as f:\n",
        "  raw_data = json.load(f)\n",
        "  for k,v in raw_data.items():\n",
        "    target_idxs.add(k)\n",
        "    category_idxs.add(v)\n",
        "\n",
        "import random\n",
        "rand_idx = random.randint(0,len(category_idxs)-1)\n",
        "category_idx = list(category_idxs)[rand_idx]\n",
        "\n",
        "print(f'select category_idx: {category_idx}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup login in HF"
      ],
      "metadata": {
        "id": "n-PIs49nzouW"
      },
      "id": "n-PIs49nzouW"
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "import os\n",
        "HF_TOKEN = userdata.get(\"HF_TOKEN\")\n",
        "login(HF_TOKEN)\n",
        "hf_api = HfApi(token=HF_TOKEN)"
      ],
      "metadata": {
        "id": "ypvFNDlnzqi-"
      },
      "id": "ypvFNDlnzqi-",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running pipeline"
      ],
      "metadata": {
        "id": "CPuHgTv87y2l"
      },
      "id": "CPuHgTv87y2l"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "1ab9b8a8",
      "metadata": {
        "id": "1ab9b8a8",
        "outputId": "b3ba47e8-0be0-4a9e-f50e-0eca81f4b80f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running pipeline for 31 categories\n",
            "select category for batch: Clothing_Shoes_and_Jewelry\n",
            "select category for batch: CDs_and_Vinyl\n",
            "select category for batch: Sports_and_Outdoors\n",
            "select category for batch: Patio_Lawn_and_Garden\n",
            "select category for batch: Amazon_Fashion\n",
            "select category for batch: Automotive\n",
            "select category for batch: Appliances\n",
            "select category for batch: Toys_and_Games\n",
            "select category for batch: All_Beauty\n",
            "select category for batch: Books\n",
            "select category for batch: Pet_Supplies\n",
            "select category for batch: Grocery_and_Gourmet_Food\n",
            "select category for batch: Industrial_and_Scientific\n",
            "select category for batch: Home_and_Kitchen\n",
            "select category for batch: Tools_and_Home_Improvement\n",
            "select category for batch: Health_and_Household\n",
            "select category for batch: Magazine_Subscriptions\n",
            "select category for batch: Handmade_Products\n",
            "select category for batch: Arts_Crafts_and_Sewing\n",
            "select category for batch: Movies_and_TV\n",
            "select category for batch: Gift_Cards\n",
            "select category for batch: Musical_Instruments\n",
            "select category for batch: Baby_Products\n",
            "select category for batch: Software\n",
            "select category for batch: Health_and_Personal_Care\n",
            "select category for batch: Beauty_and_Personal_Care\n",
            "select category for batch: Cell_Phones_and_Accessories\n",
            "select category for batch: Office_Products\n",
            "select category for batch: Electronics\n",
            "select category for batch: Kindle_Store\n",
            "select category for batch: Video_Games\n"
          ]
        }
      ],
      "source": [
        "list_category_idxs = list(category_idxs)\n",
        "print(f\"Running pipeline for {len(list_category_idxs)} categories\")\n",
        "\n",
        "for i in range(len(list_category_idxs)):\n",
        "  logger = logging.getLogger(f'Pipeline for fetch reviews data for batch number {i+1} ')\n",
        "  logger.setLevel(logging.DEBUG)\n",
        "  category_idx = list_category_idxs[i] if list_category_idxs[i].find(\" \") == -1 else list_category_idxs[i].replace(\" \",\"_\")\n",
        "  print(f'select category for batch: {category_idx}')\n",
        "  try:\n",
        "    repo_id = \"Talissa/AmazonC4Augmented\"\n",
        "    filename = f\"raw/review_and_meta_categories/filtered_4_star_reviews_{category_idx}.parquet\"\n",
        "    if not hf_api.file_exists(repo_id=repo_id,filename=filename,repo_type=\"dataset\"):\n",
        "      raise FileNotFoundError\n",
        "  except FileNotFoundError:\n",
        "    logger.info(\"Start pipeline\")\n",
        "    pipeline_for_fetch_reviews(category_idx,target_idxs)\n",
        "    pipeline_for_fetch_items(category_idx,target_idxs)\n",
        "    df_items = pd.read_parquet(f'/content/dataset/raw/meta_categories/filtered_items_{category_idx}.parquet')\n",
        "    df_reviews = pd.read_parquet(f'/content/dataset/raw/review_categories/filtered_4_star_reviews_{category_idx}.parquet')\n",
        "    df_final = build_final_dataframe(df_items,df_reviews,save_parquet=True,category_idx=category_idx)\n",
        "    logger.info(f\"Build final dataframe for {category_idx} with review and item metadata\")\n",
        "    upload_file(\n",
        "        path_or_fileobj=f\"/content/dataset/raw/review_and_meta_categories/filtered_4_star_reviews_{category_idx}.parquet\",\n",
        "        path_in_repo=f\"/raw/review_and_meta_categories/filtered_4_star_reviews_{category_idx}.parquet\",\n",
        "        repo_id=\"Talissa/AmazonC4Augmented\",\n",
        "        repo_type=\"dataset\",\n",
        "        commit_message=\"Add files in repo\"\n",
        "    )\n",
        "    logger.info(f\"Added parquet file /raw/review_and_meta_categories/filtered_4_star_reviews_{category_idx}.parquet\")\n",
        "    logger.info(\"End pipeline\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}