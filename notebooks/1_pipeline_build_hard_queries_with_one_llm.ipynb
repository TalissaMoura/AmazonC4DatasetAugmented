{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TalissaMoura/AmazonC4DatasetAugmented/blob/main/notebooks/1_pipeline_build_hard_queries_with_one_llm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a722754",
      "metadata": {
        "id": "0a722754"
      },
      "source": [
        "# Pipeline for build the hard queries"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0ea38d3",
      "metadata": {
        "id": "e0ea38d3"
      },
      "source": [
        "# 2. Functions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install outlines"
      ],
      "metadata": {
        "id": "frB7FQtLRmTg",
        "outputId": "6b85194a-6af1-4680-d869-fc0b1dc996e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "frB7FQtLRmTg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: outlines in /usr/local/lib/python3.12/dist-packages (1.2.9)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from outlines) (3.1.6)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from outlines) (3.1.2)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.12/dist-packages (from outlines) (5.6.3)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.12/dist-packages (from outlines) (2.12.3)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.12/dist-packages (from outlines) (4.25.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from outlines) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from outlines) (4.15.0)\n",
            "Requirement already satisfied: outlines_core==0.2.11 in /usr/local/lib/python3.12/dist-packages (from outlines) (0.2.11)\n",
            "Requirement already satisfied: genson in /usr/local/lib/python3.12/dist-packages (from outlines) (1.3.0)\n",
            "Requirement already satisfied: jsonpath_ng in /usr/local/lib/python3.12/dist-packages (from outlines) (1.7.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->outlines) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->outlines) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->outlines) (0.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->outlines) (3.0.3)\n",
            "Requirement already satisfied: ply in /usr/local/lib/python3.12/dist-packages (from jsonpath_ng->outlines) (3.11)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema->outlines) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema->outlines) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema->outlines) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema->outlines) (0.30.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optmum, gptqmodel"
      ],
      "metadata": {
        "id": "tfEftuyrFHpK"
      },
      "id": "tfEftuyrFHpK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, re, torch, pathlib, time\n",
        "import outlines\n",
        "from huggingface_hub import login,snapshot_download, upload_file, HfApi\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from google.colab import userdata\n",
        "import pandas as pd\n",
        "import pyarrow as pa\n",
        "import pyarrow.dataset as ds\n",
        "import pyarrow.parquet as pq\n",
        "from pydantic import BaseModel,ValidationError"
      ],
      "metadata": {
        "id": "y_L1JiSJQnIK"
      },
      "id": "y_L1JiSJQnIK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef1c30b2",
      "metadata": {
        "id": "ef1c30b2"
      },
      "outputs": [],
      "source": [
        "class ProductReviewOutline(BaseModel):\n",
        "    positive_points: list[str]\n",
        "    negative_points: list[str]\n",
        "\n",
        "class HardNegativeQuery(BaseModel):\n",
        "    query: str\n",
        "\n",
        "def extract_json_from_markdown(response_text: str) -> str:\n",
        "    \"\"\"Extract JSON from markdown code blocks\"\"\"\n",
        "    # Look for ```json ... ``` or ``` ... ```\n",
        "    pattern = r'```(?:json)?\\s*(.*?)\\s*```'\n",
        "    matches = re.findall(pattern, response_text, re.DOTALL)\n",
        "\n",
        "    if matches:\n",
        "        # Return the first JSON block found\n",
        "        return matches[0].strip()\n",
        "    else:\n",
        "        # If no markdown blocks, return original text\n",
        "        return response_text\n",
        "\n",
        "def clean_and_parse_json(response_text: str,pydantic_model:BaseModel) -> BaseModel | None:\n",
        "    # Step 1: Extract JSON from markdown if present\n",
        "    json_content = extract_json_from_markdown(response_text)\n",
        "\n",
        "    # Step 2: Remove any remaining backticks or markdown artifacts\n",
        "    json_content = json_content.strip()\n",
        "\n",
        "    # Step 3: Handle potential escaping issues\n",
        "    if json_content.startswith('\"') and json_content.endswith('\"'):\n",
        "        # Unescape if it's still a string representation\n",
        "        try:\n",
        "            json_content = json.loads(json_content)\n",
        "        except json.JSONDecodeError:\n",
        "            pass  # Keep as is if it's not double-escaped\n",
        "\n",
        "    # Step 4: Parse and validate\n",
        "    try:\n",
        "        if isinstance(json_content, str):\n",
        "            return pydantic_model.model_validate_json(json_content)\n",
        "        else:\n",
        "            return pydantic_model.model_validate(json_content)\n",
        "    except ValidationError as e:\n",
        "        print(f\"Validation error: {e}\")\n",
        "        return None\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"JSON decode error: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def load_model(model_name):\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_name,trust_remote_code=True,device_map=\"auto\",dtype=\"auto\")\n",
        "  model = AutoModelForCausalLM.from_pretrained(model_name,trust_remote_code=True,device_map=\"auto\",dtype=\"auto\")\n",
        "\n",
        "  # ðŸ” Validate placement\n",
        "  if not next(model.parameters()).is_cuda:\n",
        "      raise RuntimeError(\"Model failed to load on GPU!\")\n",
        "  print(\"âœ… Model successfully on GPU.\")\n",
        "  print(f\"âœ… Model loaded on {next(model.parameters()).device} | Dtype: {next(model.parameters()).dtype}\")\n",
        "  return model,tokenizer\n",
        "\n",
        "\n",
        "def generate_positive_and_negative_points_for_reviews(\n",
        "    df_reviews,\n",
        "    model,\n",
        "    tokenizer,\n",
        "    category,\n",
        "    model_name,\n",
        "    save_local=True,\n",
        "    system_template_path=\"/content/prompts/system_prompt_review_analysis.txt\",\n",
        "    user_template_path=\"/content/prompts/user_prompt_review_analysis.txt\",\n",
        "    batch_size=12  # â† tune: L4 handles 8â€“16 for 3B\n",
        "):\n",
        "    # Pre-load templates once\n",
        "    system_template = outlines.Template.from_file(system_template_path)\n",
        "    user_template = outlines.Template.from_file(user_template_path)\n",
        "\n",
        "    batches = df_reviews.to_batches()\n",
        "    for i, batch in enumerate(batches):\n",
        "        rows = batch.to_pylist()\n",
        "        new_rows = [None] * len(rows)\n",
        "\n",
        "        # Prepare all messages first\n",
        "        all_messages = []\n",
        "        for row in rows:\n",
        "            positive_review = \"\\n , \".join(row['ori_positive_review'])\n",
        "            semi_positive_reviews = \"\\n , \".join(row['ori_semi_positive_review'])\n",
        "            messages = [\n",
        "                {\"role\": \"system\", \"content\": system_template()},\n",
        "                {\"role\": \"user\", \"content\": user_template(\n",
        "                    very_positive_review=positive_review,\n",
        "                    somewhat_positive_review=semi_positive_reviews\n",
        "                )}\n",
        "            ]\n",
        "            all_messages.append(messages)\n",
        "\n",
        "        # Process in chunks (to avoid OOM on large batches)\n",
        "        for start in range(0, len(all_messages), batch_size):\n",
        "            end = start + batch_size\n",
        "            chunk_messages = all_messages[start:end]\n",
        "            chunk_results = generate_and_parse_batch_with_retry(\n",
        "                model=model,\n",
        "                tokenizer=tokenizer,\n",
        "                batch_messages=chunk_messages,\n",
        "                pydantic_model=ProductReviewOutline,\n",
        "                max_attempts=3,\n",
        "                max_new_tokens=384,  # â†“ reduce if possible\n",
        "                batch_size=batch_size\n",
        "            )\n",
        "            new_rows[start:end] = chunk_results\n",
        "\n",
        "        # Reconstruct data with results\n",
        "        new_data = []\n",
        "        for row, parsed in zip(rows, new_rows):\n",
        "            if parsed:\n",
        "                row['positive_points'] = parsed.positive_points\n",
        "                row['negative_points'] = parsed.negative_points\n",
        "                new_data.append(row)\n",
        "            else:\n",
        "                print(f\"âš ï¸ Failed to parse for row {start + i}\")\n",
        "\n",
        "        # Save\n",
        "        if save_local and new_data:\n",
        "            save_dir = f\"/content/datasets/procesed/review_analysis/{model_name}\"\n",
        "            pathlib.Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
        "            batch_table = pa.Table.from_pylist(new_data)\n",
        "            pq.write_table(batch_table, f\"{save_dir}/{category}_review_analysis_part_{i}.parquet\")\n",
        "        print(f\"âœ… Batch {i} done ({len(new_data)}/{len(rows)} succeeded).\")\n",
        "\n",
        "from typing import List, Tuple, Optional\n",
        "import torch\n",
        "\n",
        "def generate_and_parse_batch_with_retry(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    batch_messages: List[List[dict]],  # List of message lists\n",
        "    pydantic_model: BaseModel,\n",
        "    max_attempts: int = 3,\n",
        "    max_new_tokens: int = 2048,\n",
        "    batch_size: Optional[int] = None,  # auto if None\n",
        ") -> List[Optional[BaseModel]]:\n",
        "    \"\"\"\n",
        "    Process a batch of prompts with per-sample retries.\n",
        "    Returns list of parsed models (or None on failure).\n",
        "    \"\"\"\n",
        "    device = model.device\n",
        "    results: List[Optional[BaseModel]] = [None] * len(batch_messages)\n",
        "    remaining_indices = list(range(len(batch_messages)))\n",
        "\n",
        "    for attempt in range(1, max_attempts + 1):\n",
        "        if not remaining_indices:\n",
        "            break\n",
        "\n",
        "        # Get current batch of messages to process\n",
        "        current_messages = [batch_messages[i] for i in remaining_indices]\n",
        "\n",
        "        # Format prompts (apply_chat_template for all)\n",
        "        prompts = [\n",
        "            tokenizer.apply_chat_template(\n",
        "                msgs,\n",
        "                tokenize=False,\n",
        "                add_generation_prompt=True\n",
        "            )\n",
        "            for msgs in current_messages\n",
        "        ]\n",
        "\n",
        "        # Tokenize with padding (critical for batch)\n",
        "        model_inputs = tokenizer(\n",
        "            prompts,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "        ).to(device)\n",
        "\n",
        "        # Generate\n",
        "        with torch.no_grad():\n",
        "            generated_ids = model.generate(\n",
        "                **model_inputs,\n",
        "                max_new_tokens=max_new_tokens,\n",
        "                pad_token_id=tokenizer.eos_token_id,\n",
        "                do_sample=False,\n",
        "                temperature=0.0,\n",
        "            )\n",
        "\n",
        "        # Trim input tokens\n",
        "        input_lengths = model_inputs.input_ids.shape[1]\n",
        "        generated_texts = tokenizer.batch_decode(\n",
        "            generated_ids[:, input_lengths:],  # trim inputs\n",
        "            skip_special_tokens=True\n",
        "        )\n",
        "\n",
        "        # Parse each response individually\n",
        "        new_remaining = []\n",
        "        for idx_in_batch, (global_idx, response) in enumerate(zip(remaining_indices, generated_texts)):\n",
        "            try:\n",
        "                parsed = clean_and_parse_json(response, pydantic_model)\n",
        "                if parsed is not None:\n",
        "                    results[global_idx] = parsed\n",
        "                else:\n",
        "                    # Parse failed â†’ keep for retry\n",
        "                    new_remaining.append(global_idx)\n",
        "            except Exception as e:\n",
        "                print(f\"[Batch attempt {attempt}] Parse error for idx {global_idx}: {e}\")\n",
        "                new_remaining.append(global_idx)\n",
        "\n",
        "        remaining_indices = new_remaining\n",
        "\n",
        "        if remaining_indices and attempt < max_attempts:\n",
        "            time.sleep(0.2)  # optional: small delay\n",
        "\n",
        "    return results\n",
        "\n",
        "def generate_hard_negative_queries(\n",
        "    df_reviews,\n",
        "    model,\n",
        "    tokenizer,\n",
        "    category,\n",
        "    model_name,\n",
        "    save_local=True,\n",
        "    system_template_path=\"/content/prompts/system_prompt_generate_hard_negative_queries.txt\",\n",
        "    user_template_path=\"/content/prompts/user_prompt_generate_hard_negative_queries.txt\",\n",
        "    per_row_queries=3,\n",
        "    batch_size=8\n",
        "):\n",
        "    system_template = outlines.Template.from_file(system_template_path)\n",
        "    user_template = outlines.Template.from_file(user_template_path)\n",
        "\n",
        "    batches = df_reviews.to_batches()\n",
        "    for i, batch in enumerate(batches):\n",
        "        rows = batch.to_pylist()\n",
        "        all_messages = []\n",
        "        row_indices = []  # track which row + which query (0,1,2)\n",
        "\n",
        "        # Expand: 1 row â†’ 3 prompts\n",
        "        for row_idx, row in enumerate(rows):\n",
        "            pos_list = \",\".join(row['positive_points'] or [])\n",
        "            neg_list = \",\".join(row['negative_points'] or [])\n",
        "            for q_idx in range(per_row_queries):\n",
        "                messages = [\n",
        "                    {\"role\": \"system\", \"content\": system_template()},\n",
        "                    {\"role\": \"user\", \"content\": user_template(\n",
        "                        positive_list=pos_list,\n",
        "                        negative_list=neg_list\n",
        "                    )}\n",
        "                ]\n",
        "                all_messages.append(messages)\n",
        "                row_indices.append((row_idx, q_idx))\n",
        "\n",
        "        # Process in chunks\n",
        "        all_results = [None] * len(all_messages)\n",
        "        for start in range(0, len(all_messages), batch_size):\n",
        "            end = start + batch_size\n",
        "            chunk = all_messages[start:end]\n",
        "            res = generate_and_parse_batch_with_retry(\n",
        "                model, tokenizer, chunk, HardNegativeQuery,\n",
        "                max_attempts=3, max_new_tokens=384, batch_size=batch_size\n",
        "            )\n",
        "            all_results[start:end] = res\n",
        "\n",
        "        # Reconstruct: group by original row\n",
        "        new_rows = []\n",
        "        for row_idx, row in enumerate(rows):\n",
        "            queries = []\n",
        "            for q_idx in range(per_row_queries):\n",
        "                global_idx = row_idx * per_row_queries + q_idx\n",
        "                parsed = all_results[global_idx]\n",
        "                if parsed:\n",
        "                    queries.append(parsed.query)\n",
        "            # Keep original row + all successful queries\n",
        "            for query in queries:\n",
        "                new_row = {**row, \"hard_negative_query\": query}\n",
        "                new_rows.append(new_row)\n",
        "\n",
        "        # Save\n",
        "        if save_local and new_rows:\n",
        "            save_dir = f\"/content/datasets/procesed/hard_negative_queries/{model_name}\"\n",
        "            pathlib.Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
        "            pq.write_table(\n",
        "                pa.Table.from_pylist(new_rows),\n",
        "                f\"{save_dir}/{category}_part_{i}.parquet\"\n",
        "            )\n",
        "        print(f\"âœ… Batch {i}: {len(new_rows)} hard queries generated.\")\n",
        "\n",
        "\n",
        "\n",
        "def save_file_in_remote(local_filepath,remote_filepath):\n",
        "  upload_file(\n",
        "      path_or_fileobj=f\"{local_filepath}\",\n",
        "      path_in_repo=f\"{remote_filepath}\",\n",
        "      repo_id=\"Talissa/AmazonC4Augmented\",\n",
        "      repo_type=\"dataset\",\n",
        "      commit_message=f\"Add {remote_filepath}\"\n",
        "  )\n",
        "  print(\"File saved locally\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pipeline_for_generate_hard_queries(idx_category,model,model_name,tokenizer):\n",
        "\n",
        "  print(f\"Load the reviews for category: {idx_category}\")\n",
        "  try:\n",
        "    snapshot_download(\n",
        "        repo_id='Talissa/AmazonC4Augmented',\n",
        "        repo_type=\"dataset\",\n",
        "        local_dir='/content/datasets',\n",
        "        allow_patterns=[f'raw/review_and_meta_categories/filtered_4_star_reviews_{idx_category}.parquet']\n",
        "    )\n",
        "  except Exception as e:\n",
        "    print(f\"Error download the file: {e}\")\n",
        "\n",
        "  df_amazonc4 = load_dataset('McAuley-Lab/Amazon-C4')['test'].data.table\n",
        "  df_reviews = pq.read_table(f'/content/datasets/raw/review_and_meta_categories/filtered_4_star_reviews_{idx_category}.parquet')\n",
        "  df_all_reviews = df_amazonc4.select(['item_id','ori_review']).rename_columns({'ori_review':'ori_positive_review'}).join(\n",
        "    df_reviews.select(['asin','ori_review']).rename_columns({'asin':'item_id','ori_review':'ori_semi_positive_review'}),\n",
        "    join_type='inner',\n",
        "    keys=['item_id']\n",
        "    )\n",
        "\n",
        "  df_final = df_all_reviews.group_by(\"item_id\").aggregate([\n",
        "      (\"ori_semi_positive_review\", \"list\"),\n",
        "      (\"ori_positive_review\", \"distinct\")\n",
        "  ])\n",
        "\n",
        "  df_final = df_final.rename_columns({\n",
        "      'ori_semi_positive_review_list':'ori_semi_positive_review',\n",
        "      'ori_positive_review_distinct':'ori_positive_review'\n",
        "  })\n",
        "\n",
        "  print(f\"--- Generate positive and negative points for reviews: {idx_category} ---\")\n",
        "  generate_positive_and_negative_points_for_reviews(df_final,model,tokenizer,idx_category,model_name=model_name)\n",
        "\n",
        "  df_all_reviews_cat = [\n",
        "    pq.read_table(f) for f in list(pathlib.Path(f'/content/datasets/procesed/review_analysis/{model_name}').glob(f'{idx_category}_review_analysis_part_*.parquet'))\n",
        "    ]\n",
        "  df_batch = pa.concat_tables(df_all_reviews_cat)\n",
        "\n",
        "  print(f\"--- Generate hard negative queries: {idx_category} ---\")\n",
        "  generate_hard_negative_queries(df_batch,model,tokenizer,idx_category,model_name=model_name)\n",
        "\n",
        "\n",
        "  return f'finish pipeline for category: {idx_category}'\n"
      ],
      "metadata": {
        "id": "Dvij0608mxpF"
      },
      "id": "Dvij0608mxpF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup hugging faces\n",
        "from huggingface_hub import login,snapshot_download, upload_file, HfApi\n",
        "from google.colab import userdata\n",
        "import os\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "login(HF_TOKEN)\n",
        "hf_api = HfApi(token=HF_TOKEN)"
      ],
      "metadata": {
        "id": "S-HL1ImY25ty"
      },
      "id": "S-HL1ImY25ty",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1ae8cac8",
      "metadata": {
        "id": "1ae8cac8"
      },
      "source": [
        "# 3. Load data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download asin2category file\n",
        "try:\n",
        "  snapshot_download(\n",
        "      repo_id='Talissa/AmazonC4Augmented',\n",
        "      repo_type='dataset',\n",
        "      local_dir='datasets',\n",
        "      allow_patterns=['asin2categoryfiltered.json'],\n",
        "      token=HF_TOKEN)\n",
        "except Exception as e:\n",
        "  print(f'Error download the file: {e}')\n",
        "\n",
        "\n",
        "with open(f'/content/datasets/asin2categoryfiltered.json', 'r') as f:\n",
        "  asin2category = json.load(f)\n",
        "\n",
        "all_categories = list(asin2category.values())\n",
        "all_categories = list(set(all_categories))\n",
        "cat_sort = sorted(all_categories)\n",
        "cat_treated = []\n",
        "for cat in cat_sort:\n",
        "  if cat.find(\" \"):\n",
        "    cat = cat.replace(\" \",\"_\")\n",
        "    cat_treated.append(cat)\n",
        "  else:\n",
        "    cat_treated.append(cat)\n",
        "print(f\"Load all the {len(cat_treated)} categories\")"
      ],
      "metadata": {
        "id": "7Ah0aEF21iJs",
        "outputId": "803a3f7a-12f2-465a-c220-1aefd28c00bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "ccf83d7cd81349a0a946953f9d89430b",
            "48b4f1db4b1843af8775970ab7cb029d",
            "527fec3940764182a35cb760f86ff5eb",
            "3002aa114a7e41c2807f1b0b53bd220e",
            "d58ac2d1f0ce4bd888399452f9cd0634",
            "84d06c21edf44f49aeed72e0cb66cdc4",
            "f84807ef4c014686906a17fab7241329",
            "0efe8021290141e2a13fd7f9734e2726",
            "333e59bb1dcd4c4884e3a7347ceeb65e",
            "d3bfeef964ff4932a95e329c697a4a50",
            "4a403e40ae8b45a1890949e465ed0a3d"
          ]
        }
      },
      "id": "7Ah0aEF21iJs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ccf83d7cd81349a0a946953f9d89430b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load all the 31 categories\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Build the pipeline"
      ],
      "metadata": {
        "id": "kyZsDsZfIu4X"
      },
      "id": "kyZsDsZfIu4X"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 - Build prompts"
      ],
      "metadata": {
        "id": "LYR1aTdbfaDN"
      },
      "id": "LYR1aTdbfaDN"
    },
    {
      "cell_type": "code",
      "source": [
        "import outlines, pathlib\n",
        "\n",
        "if not pathlib.Path('/content/prompts/').exists():\n",
        "  pathlib.Path.mkdir('/content/prompts')\n",
        "\n",
        "try:\n",
        "  repo_id = \"Talissa/AmazonC4Augmented\"\n",
        "  filename = f\"prompts/system_prompt_analysis_review\"\n",
        "  if not hf_api.file_exists(repo_id=repo_id,filename=filename,repo_type=\"dataset\"):\n",
        "    raise FileNotFoundError\n",
        "except FileNotFoundError:\n",
        "    system_template = \\\n",
        "    \"\"\"\n",
        "    ```json\n",
        "      {\n",
        "      \"role\": \"You are a Review Contrast Analyst specialized in e-commerce feedback.\",\n",
        "      \"task\": \"Compare two sets of user reviews for the same product: one labeled 'very_positive' (high satisfaction), the other 'somewhat_positive' (moderate satisfaction). Extract and contrast the key positive and negative aspects that explain this difference in sentiment.\",\n",
        "      \"instructions\": [\n",
        "        \"1. Phrase each point as a concise, canonical noun-phrase (e.g., 'strong odor on first use') â€” avoid verbs like 'is', 'has', 'feels'.\",\n",
        "        \"2. For negative points, prefer *constructive phrasing* (e.g., 'initial chemical smell' instead of 'smells bad').\",\n",
        "        \"3. Ground every point with an evidence span (short verbatim quote).\",\n",
        "        \"4. Do NOT include generic praise (e.g., 'good product', 'recommended') unless tied to a specific feature.\"\n",
        "      ],\n",
        "      \"input_format\": {\n",
        "        \"very_positive_review\": [\"string\", \"...\"],\n",
        "        \"somewhat_positive_review\": [\"string\", \"...\"]\n",
        "      },\n",
        "      \"output_format\": {\n",
        "        \"positive_points\": [\n",
        "            \"string â€” canonical phrase, e.g., 'lightweight and flexible sole'\"\n",
        "        ],\n",
        "        \"negative_points\": [\n",
        "          \"string â€” constructive phrasing, e.g., 'noticeable warmth buildup after 15 minutes'\"\n",
        "        ]\n",
        "      },\n",
        "      \"requirements\": [\n",
        "        \"Max 6 positive and 6 negative points total.\",\n",
        "        \"If a point is only implied (not stated), omit it.\",\n",
        "        \"If in the review, use where the person use the product (i.e instead of \"love these boots\" write \"love these boots for raining days\") \",\n",
        "        \"Prioritize points that *explain the sentiment gap* (e.g., negatives only in 'somewhat_positive' are high-value).\",\n",
        "        \"Return ONLY valid JSON. No markdown, no explanations.\"\n",
        "      ]\n",
        "    }\n",
        "    ```\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    with open('/content/prompts/system_prompt_review_analysis.txt', 'w+') as f:\n",
        "          f.write(system_template)\n",
        "          f.close()\n",
        "          upload_file(\n",
        "              path_or_fileobj=f\"/content/prompts/system_prompt_review_analysis.txt\",\n",
        "              path_in_repo=f\"prompts/system_template_review_analysis.txt\",\n",
        "              repo_id=\"Talissa/AmazonC4Augmented\",\n",
        "              repo_type=\"dataset\",\n",
        "              commit_message=\"Add system prompt for review analysis\"\n",
        "          )\n"
      ],
      "metadata": {
        "id": "OcTYrOKq2wve",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b6fa098-870a-44d6-c2fc-b5e6c75ee8c6"
      },
      "id": "OcTYrOKq2wve",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  repo_id = \"Talissa/AmazonC4Augmented\"\n",
        "  filename = f\"prompts/user_prompt_review_analysis\"\n",
        "  if not hf_api.file_exists(repo_id=repo_id,filename=filename,repo_type=\"dataset\"):\n",
        "    raise FileNotFoundError\n",
        "except FileNotFoundError:\n",
        "    user_template = \\\n",
        "    \"\"\"\n",
        "    ```json\n",
        "    {\n",
        "\n",
        "      \"very_positive_review\": [{{very_positive_review}}],\n",
        "\n",
        "      \"somewhat_positive_review\": [{{somewhat_positive_review}}]\n",
        "\n",
        "    }\n",
        "    ```\n",
        "    \"\"\"\n",
        "\n",
        "    with open('/content/prompts/user_prompt_review_analysis.txt', 'w') as f:\n",
        "          f.write(user_template)\n",
        "          f.close()\n",
        "          upload_file(\n",
        "              path_or_fileobj=f\"/content/prompts/user_prompt_review_analysis.txt\",\n",
        "              path_in_repo=f\"prompts/user_prompt_review_analysis.txt\",\n",
        "              repo_id=\"Talissa/AmazonC4Augmented\",\n",
        "              repo_type=\"dataset\",\n",
        "              commit_message=\"Add user prompt for review analysis\"\n",
        "          )\n"
      ],
      "metadata": {
        "id": "KaFJRNlO4OL6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "582dd801-fba3-475f-8a01-77bfaecb6275"
      },
      "id": "KaFJRNlO4OL6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not pathlib.Path('/content/prompts/').exists():\n",
        "  pathlib.Path.mkdir('/content/prompts')\n",
        "\n",
        "try:\n",
        "  repo_id = \"Talissa/AmazonC4Augmented\"\n",
        "  filename = f\"prompts/system_prompt_generate_hard_negative_queries\"\n",
        "  if not hf_api.file_exists(repo_id=repo_id,filename=filename,repo_type=\"dataset\"):\n",
        "    raise FileNotFoundError\n",
        "except FileNotFoundError:\n",
        "    system_template = \\\n",
        "    \"\"\"\n",
        "    ```json\n",
        "    {\n",
        "  \"task\": \"You are a text generator. You receive two lists: one containing positive aspects and another containing negative aspects of a product purchased online, from the user's point of view. Based on these lists, generate a first-person, natural-language search query â€” phrased as if a real person were typing it into a search engine or speaking aloud to a friend.\",\n",
        "  \"input_format\": {\n",
        "    \"positive_characteristics_list\": \"[string] â€” comma-separated list of positive aspects: features, benefits, or qualities the user appreciated.\",\n",
        "    \"negative_characteristics_list\": \"[string] â€” comma-separated list of negative aspects: drawbacks, failures, or dealbreakers the user experienced.\"\n",
        "  },\n",
        "  \"output_type\": \"str\",\n",
        "  \"output_format\": {\n",
        "    \"query\": \"string â€” a single, fluent, first-person search query in natural spoken/written language\"\n",
        "  },\n",
        "  \"requirements\": [\n",
        "    \"The query must sound authentically human: use contractions (e.g., 'Iâ€™m', 'donâ€™t'), colloquial phrasing, and optional interjections (e.g., 'Honestlyâ€¦', 'Looking forâ€¦') â€” but avoid slang or region-specific idioms unless implied by context.\",\n",
        "    \"Explicitly embed ONE positive aspect from `positive_list` as a *desired feature* â€” phrase it functionally (e.g., 'good grip' instead of 'I liked the grip').\",\n",
        "    \"Explicitly address ONE negative aspect from `negative_list` as an *avoidance or improvement goal* â€” rephrase negatives constructively (e.g., 'that doesnâ€™t slip when wet' instead of 'not slippery').\",\n",
        "    \"Rephrase the selected positive and negative aspects by adding realistic, everyday context â€” such as *where*, *when*, or *how* the user plans to use the product â€” to ground the query in a concrete scenario (e.g., 'I need hiking shoes with solid ankle support that donâ€™t give me blisters after 5 miles on rocky trails' instead of just 'shoes with support and no blisters'). Avoid hypothetical, exaggerated, or unsafe scenarios.\",\n",
        "    \"Do NOT list multiple positives/negatives â€” focus on ONE positive + ONE negative to keep the query focused and high-signal.\",\n",
        "    \"Avoid generic terms like 'good', 'great', 'quality' unless directly tied to a concrete attribute (e.g., 'good cushioning' is OK; 'good quality' is not).\",\n",
        "    \"The final query must be usable as-is in a real e-commerce search bar or voice assistant â€” no markdown, quotes, or extra punctuation beyond natural usage.\",\n",
        "    \"Return ONLY a valid JSON object with the key `query`. No explanations, prefixes, or suffixes.\"\n",
        "  ]\n",
        "}\n",
        "```\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    with open('/content/prompts/system_prompt_generate_hard_negative_queries.txt', 'w+') as f:\n",
        "          f.write(system_template)\n",
        "          f.close()\n",
        "          upload_file(\n",
        "              path_or_fileobj=f\"/content/prompts/system_prompt_generate_hard_negative_queries.txt\",\n",
        "              path_in_repo=f\"prompts/system_prompt_generate_hard_negative_queries.txt\",\n",
        "              repo_id=\"Talissa/AmazonC4Augmented\",\n",
        "              repo_type=\"dataset\",\n",
        "              commit_message=\"Add system prompt for generate hard negative queries\"\n",
        "          )\n"
      ],
      "metadata": {
        "id": "RaHdkkWu23GK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ca0ad48-ba1d-4d9c-a422-86539f816420"
      },
      "id": "RaHdkkWu23GK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  repo_id = \"Talissa/AmazonC4Augmented\"\n",
        "  filename = f\"prompts/user_prompt_generate_hard_negative_queries\"\n",
        "  if not hf_api.file_exists(repo_id=repo_id,filename=filename,repo_type=\"dataset\"):\n",
        "    raise FileNotFoundError\n",
        "except FileNotFoundError:\n",
        "    user_template = \\\n",
        "    \"\"\"\n",
        "    ```json\n",
        "    positive_characteristics_list -: \\n [{{positive_list}}] \\n\n",
        "\n",
        "    negative_characteristics_list -: \\n [{{negative_list}}] \\n\n",
        "    ```\n",
        "    \"\"\"\n",
        "\n",
        "    with open('/content/prompts/user_prompt_generate_hard_negative_queries.txt', 'w') as f:\n",
        "          f.write(user_template)\n",
        "          f.close()\n",
        "          upload_file(\n",
        "              path_or_fileobj=f\"/content/prompts/user_prompt_generate_hard_negative_queries.txt\",\n",
        "              path_in_repo=f\"prompts/user_prompt_generate_hard_negative_queries.txt\",\n",
        "              repo_id=\"Talissa/AmazonC4Augmented\",\n",
        "              repo_type=\"dataset\",\n",
        "              commit_message=\"Add user prompt for generate hard negative queries\"\n",
        "          )\n"
      ],
      "metadata": {
        "id": "EzyG6THN23JB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4199612-0f19-4cb2-ac39-a253404842f7"
      },
      "id": "EzyG6THN23JB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 - Running pipeline"
      ],
      "metadata": {
        "id": "zV3qQHkt2Un6"
      },
      "id": "zV3qQHkt2Un6"
    },
    {
      "cell_type": "code",
      "source": [
        "if \"model\" not in globals():\n",
        "  MODEL_NAME = \"Qwen/Qwen2.5-7B-Instruct-GPTQ-Int4\"\n",
        "  model,tokenizer = load_model(MODEL_NAME)\n",
        "else:\n",
        "  print(\"Model already loaded\")\n",
        "\n",
        "selected_cats = [cat_treated[i] for i in range(len(cat_treated))]\n",
        "\n",
        "filtered_selected_cats = [\"Automotive\",\"Books\",\"Beauty_and_Personal_Care\",\"Clothing_Shoes_and_Jewelry\",\"Eletronics\"]\n",
        "\n",
        "for cat in filtered_selected_cats[2:]:\n",
        "  res = pipeline_for_generate_hard_queries(\n",
        "        idx_category=cat,\n",
        "        model=model,\n",
        "        model_name=MODEL_NAME,\n",
        "        tokenizer=tokenizer\n",
        "    )\n",
        "  print(res)\n",
        "\n",
        "  print(\"-- Save files in remote -- \")\n",
        "\n",
        "  ## Save files in remote\n",
        "  model_name = MODEL_NAME\n",
        "  base = pathlib.Path(f'/content/datasets/procesed/hard_negative_queries/{model_name}')\n",
        "  hq_files = [str(f) for f in list(base.glob(f'{cat}_part_*.parquet'))]\n",
        "  hq_remote_files = [\n",
        "      f\"/datasets/procesed/hard_negative_queries/{model_name}/{cat}_part_{i}.parquet\" for i in range(len(hq_files))\n",
        "  ]\n",
        "\n",
        "  for local,remote in zip(hq_files,hq_remote_files):\n",
        "    save_file_in_remote(local,remote)\n",
        "\n",
        "  print(f\"-- save hard negative queries for {cat} --\")\n",
        "\n",
        "  base_review_analysis = pathlib.Path(f'/content/datasets/procesed/review_analysis/{model_name}')\n",
        "  base_review_analysis_remote = pathlib.Path(f'/datasets/procesed/review_analysis/{model_name}')\n",
        "  review_analysis_local_files = [str(f) for f in base_review_analysis.glob(f'{cat}_review_analysis_part_*.parquet')]\n",
        "  review_analysis_remote_files = [f\"/datasets/procesed/review_analysis/{model_name}/{cat}_review_analysis_part_{i}.parquet\" for i in range(len(review_analysis_local_files))]\n",
        "\n",
        "\n",
        "  for local,remote in zip(review_analysis_local_files,review_analysis_remote_files):\n",
        "    print(local,remote)\n",
        "    save_file_in_remote(local,remote)\n",
        "\n",
        "  print(f\"-- save review analysis for {cat} --\")\n",
        "\n",
        "  print(f\"Done for {cat}\")\n",
        "\n",
        "  print(f\"Delete files for /datasets/procesed/hard_negative_queries/{model_name}\")\n",
        "  for f in hq_files:\n",
        "    pathlib.Path(f).unlink(missing_ok=True)\n",
        "  print(f\"Delete files for /datasets/procesed/review_analysis/{model_name}\")\n",
        "  for f in review_analysis_local_files:\n",
        "    pathlib.Path(f).unlink(missing_ok=True)\n",
        "\n",
        "  print(\"-- Clear raw ---\")\n",
        "  base_raw = pathlib.Path('/content/datasets/raw')\n",
        "  base_raw_local_files = [str(f) for f in base_raw.glob(f'review_and_meta_categories/filtered_4_star_reviews_{cat}*.parquet')]\n",
        "  for f in base_raw_local_files:\n",
        "    pathlib.Path(f).unlink(missing_ok=True)"
      ],
      "metadata": {
        "id": "Raj2aQINuM9V",
        "outputId": "0cad1191-667f-4452-f59f-3de8961eefed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d966ea57023045c8973a37206e403b22",
            "388e93b2b2374b4bba40351c3616a229",
            "b73801b41d92409aa2cd5dd2338c86e1",
            "d7ea92c748e24b318e991338828af7a4",
            "41280cf6e94c44f38643e2302500cd76",
            "e74f58337c1240b2a118f1b75a5782ef",
            "060bbfaf596c4731bb6929d01a866cad",
            "fe0dd01f1a144cf082afd7017ac09786",
            "ee4d3a49a78c48a1979d2c71301e6ccc",
            "cfe2fd4591e94c55a9276e20c0dcb889",
            "e7fbaa0224fc4b78bcf00df67421bf30",
            "eb2e6e3e680c4aa5adc73c6ae9376c47",
            "c388e8f5af8c4152a3fb637ee2c54aca",
            "ce42fa641ac54249a8c1696270a82ac9",
            "fee1ffe554744715a00abd100945757d",
            "1ab0e248ea304d118e04db9514c19c43",
            "76b69d5524cd4baaabbb9cdc7b8b04d2",
            "a06cc0d45cbd407da259941ea53e58b3",
            "429bbf14e96d41a995f1567ec7f2faa6",
            "3ecef27eadf545a0be9282ccdbe6abcd"
          ]
        }
      },
      "id": "Raj2aQINuM9V",
      "execution_count": 11,
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r\u001b[33mWARN\u001b[0m  Python GIL is enabled: Multi-gpu quant acceleration for MoE models is sub-optimal and multi-core accelerated cpu packing is also disabled. We recommend Python >= 3.13.3t with Pytorch > 2.8 for mult-gpu quantization and multi-cpu packing with env `PYTHON_GIL=0`.\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r\u001b[33mWARN\u001b[0m  Feature `utils/Perplexity` requires Python < 3.14 and Python GIL enabled and Python >= 3.13.3T (T for Threading-Free edition of Python) plus Torch 2.8. Feature is currently skipped/disabled.\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r\u001b[32mINFO\u001b[0m  ENV: Auto setting PYTORCH_ALLOC_CONF='expandable_segments:True,max_split_size_mb:256,garbage_collection_threshold:0.7' for memory saving.\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r\u001b[32mINFO\u001b[0m  ENV: Auto setting CUDA_DEVICE_ORDER=PCI_BUS_ID for correctness.          \n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r\u001b[36mDEBUG\u001b[0m BitBLAS import failed: No module named 'bitblas'                         \n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r\u001b[32mINFO\u001b[0m  \n",
            "\n",
            "_____/\\\\\\\\\\\\\\\\\\\\\\\\__/\\\\\\\\\\\\\\\\\\\\\\\\\\____/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\______________________/\\\\\\________/\\\\\\\\____________/\\\\\\\\_______________________/\\\\\\__________________/\\\\\\\\\\\\____\n",
            " ___/\\\\\\//////////__\\/\\\\\\/////////\\\\\\_\\///////\\\\\\/////____________________/\\\\\\\\/\\\\\\\\____\\/\\\\\\\\\\\\________/\\\\\\\\\\\\______________________\\/\\\\\\_________________\\////\\\\\\____\n",
            "  __/\\\\\\_____________\\/\\\\\\_______\\/\\\\\\_______\\/\\\\\\_______________________/\\\\\\//\\////\\\\\\__\\/\\\\\\//\\\\\\____/\\\\\\//\\\\\\______________________\\/\\\\\\____________________\\/\\\\\\____\n",
            "   _\\/\\\\\\____/\\\\\\\\\\\\\\_\\/\\\\\\\\\\\\\\\\\\\\\\\\\\/________\\/\\\\\\________/\\\\\\\\\\\\\\\\\\\\\\__/\\\\\\______\\//\\\\\\_\\/\\\\\\\\///\\\\\\/\\\\\\/_\\/\\\\\\_____/\\\\\\\\\\___________\\/\\\\\\______/\\\\\\\\\\\\\\\\_____\\/\\\\\\____\n",
            "    _\\/\\\\\\___\\/////\\\\\\_\\/\\\\\\/////////__________\\/\\\\\\_______\\///////////__\\//\\\\\\______/\\\\\\__\\/\\\\\\__\\///\\\\\\/___\\/\\\\\\___/\\\\\\///\\\\\\____/\\\\\\\\\\\\\\\\\\____/\\\\\\/////\\\\\\____\\/\\\\\\____\n",
            "     _\\/\\\\\\_______\\/\\\\\\_\\/\\\\\\___________________\\/\\\\\\______________________\\///\\\\\\\\/\\\\\\\\/___\\/\\\\\\____\\///_____\\/\\\\\\__/\\\\\\__\\//\\\\\\__/\\\\\\////\\\\\\___/\\\\\\\\\\\\\\\\\\\\\\_____\\/\\\\\\____\n",
            "      _\\/\\\\\\_______\\/\\\\\\_\\/\\\\\\___________________\\/\\\\\\________________________\\////\\\\\\//_____\\/\\\\\\_____________\\/\\\\\\_\\//\\\\\\__/\\\\\\__\\/\\\\\\__\\/\\\\\\__\\//\\\\///////______\\/\\\\\\____\n",
            "       _\\//\\\\\\\\\\\\\\\\\\\\\\\\/__\\/\\\\\\___________________\\/\\\\\\___________________________\\///\\\\\\\\\\\\__\\/\\\\\\_____________\\/\\\\\\__\\///\\\\\\\\\\/___\\//\\\\\\\\\\\\\\/\\\\__\\//\\\\\\\\\\\\\\\\\\\\__/\\\\\\\\\\\\\\\\\\_\n",
            "        __\\////////////____\\///____________________\\///______________________________\\//////___\\///______________\\///_____\\/////______\\///////\\//____\\//////////__\\/////////__\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d966ea57023045c8973a37206e403b22",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "388e93b2b2374b4bba40351c3616a229",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b73801b41d92409aa2cd5dd2338c86e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/1.58G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7ea92c748e24b318e991338828af7a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41280cf6e94c44f38643e2302500cd76",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 0 files: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to load CPU gemm_4bit kernel: Cannot install kernel from repo kernels-community/quantization_gptq (revision: main). Use fallback path.                         Please make sure you already `pip install kernels` and the kernels >= 0.11.1\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r\u001b[32mINFO\u001b[0m  Kernel: Auto-selection: adding candidate `TritonV2QuantLinear`           \n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r\u001b[32mINFO\u001b[0m  Kernel: selected -> `TritonV2QuantLinear`.                               \n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e74f58337c1240b2a118f1b75a5782ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "060bbfaf596c4731bb6929d01a866cad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/243 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r\u001b[32mINFO\u001b[0m  QuantizeConfig: offload_to_disk_path auto set to `./gptqmodel_offload/hqdpgrum-rkaakpxx/`\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r\u001b[32mINFO\u001b[0m  Format: Converting `checkpoint_format` from `FORMAT.GPTQ` to internal `FORMAT.GPTQ_V2`.\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r\u001b[32mINFO\u001b[0m  Optimize: `TritonV2QuantLinear` compilation triggered.                   \n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r\u001b[32mINFO\u001b[0m  gc.collect() reclaimed 340 objects in 0.407s                             \n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Model successfully on GPU.\n",
            "âœ… Model loaded on cuda:0 | Dtype: torch.float16\n",
            "Load the reviews for category: Beauty_and_Personal_Care\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe0dd01f1a144cf082afd7017ac09786",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee4d3a49a78c48a1979d2c71301e6ccc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "raw/review_and_meta_categories/filtered_(â€¦):   0%|          | 0.00/1.59M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cfe2fd4591e94c55a9276e20c0dcb889",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7fbaa0224fc4b78bcf00df67421bf30",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "test.csv:   0%|          | 0.00/12.5M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb2e6e3e680c4aa5adc73c6ae9376c47",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/21223 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Generate positive and negative points for reviews: Beauty_and_Personal_Care ---\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected `,` or `]` at line 15 column 69 [type=json_invalid, input_value='{\\n      \"positive_point...softer\"\\n      ]\\n    }', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected `,` or `]` at line 14 column 62 [type=json_invalid, input_value='{\\n  \"positive_points\": ...my hair softer\"\\n  ]\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected `,` or `]` at line 14 column 62 [type=json_invalid, input_value='{\\n  \"positive_points\": ...my hair softer\"\\n  ]\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected `,` or `]` at line 3 column 28 [type=json_invalid, input_value='{\\n      \"positive_point...at skin\\n      ]\\n    }', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected `,` or `]` at line 12 column 37 [type=json_invalid, input_value='{\\n      \"positive_point...enough\"\\n      ]\\n    }', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: invalid escape at line 3 column 97 [type=json_invalid, input_value='{\\n      \"positive_point...ft).\\'\"\\n      ]\\n    }', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected `,` or `]` at line 3 column 28 [type=json_invalid, input_value='{\\n      \"positive_point...at skin\\n      ]\\n    }', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected `,` or `]` at line 12 column 37 [type=json_invalid, input_value='{\\n      \"positive_point...enough\"\\n      ]\\n    }', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: invalid escape at line 3 column 93 [type=json_invalid, input_value='{\\n  \"positive_points\": ... no regrets!\\'\"\\n  ]\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected `,` or `]` at line 3 column 28 [type=json_invalid, input_value='{\\n      \"positive_point...at skin\\n      ]\\n    }', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected `,` or `]` at line 12 column 37 [type=json_invalid, input_value='{\\n      \"positive_point...enough\"\\n      ]\\n    }', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: invalid escape at line 3 column 93 [type=json_invalid, input_value='{\\n  \"positive_points\": ... no regrets!\\'\"\\n  ]\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: control character (\\u0000-\\u001F) found while parsing a string at line 12 column 0 [type=json_invalid, input_value='{\\n      \"positive_point...d 28â€\\n      ]\\n    }', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n    {\\n      \"p...on, I would say test it', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: invalid escape at line 3 column 94 [type=json_invalid, input_value='{\\n      \"positive_point...cey.\\'\"\\n      ]\\n    }', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"positive_...ould say test it\\'s use', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"positive_...ould say test it\\'s use', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected `,` or `]` at line 11 column 100 [type=json_invalid, input_value='{\\n      \"positive_point...air.\\'\"\\n      ]\\n    }', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"positive_...he 8 & 9 session. After', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"positive_...he 8 & 9 session. After', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"positive_...he 8 & 9 session. After', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: invalid escape at line 13 column 97 [type=json_invalid, input_value='{\\n      \"positive_point...body\\'\"\\n      ]\\n    }', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: invalid escape at line 13 column 84 [type=json_invalid, input_value='{\\n  \"positive_points\": ...or your body\\'\"\\n  ]\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: invalid escape at line 13 column 84 [type=json_invalid, input_value='{\\n  \"positive_points\": ...or your body\\'\"\\n  ]\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n    {\\n      \"p...ane, Cyclopentasiloxane', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"positive_...rylate, Phenoxyethanol,', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"positive_...rylate, Phenoxyethanol,', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected `,` or `]` at line 8 column 43 [type=json_invalid, input_value='{\\n      \"positive_point...r time\"\\n      ]\\n    }', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected `,` or `]` at line 3 column 24 [type=json_invalid, input_value='{\\n      \"positive_point...n hands\\n      ]\\n    }', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: invalid escape at line 14 column 89 [type=json_invalid, input_value='{\\n      \"positive_point...fore\\'\"\\n      ]\\n    }', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n    {\\n      \"p...e straps & pull it away', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: invalid escape at line 14 column 89 [type=json_invalid, input_value='{\\n      \"positive_point...fore\\'\"\\n      ]\\n    }', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected `,` or `]` at line 12 column 71 [type=json_invalid, input_value='{\\n      \"positive_point...rea.\\'\"\\n      ]\\n    }', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected `,` or `]` at line 10 column 67 [type=json_invalid, input_value='{\\n  \"positive_points\": ...n this area.\\'\"\\n  ]\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected `,` or `]` at line 10 column 67 [type=json_invalid, input_value='{\\n  \"positive_points\": ...n this area.\\'\"\\n  ]\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected `,` or `]` at line 11 column 103 [type=json_invalid, input_value='{\\n  \"positive_points\": ...'s Le Male.\"\\'\"\\n  ]\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: invalid escape at line 9 column 45 [type=json_invalid, input_value='{\\n        \"positive_poi...\\'\"\\n        ]\\n      }', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected `,` or `]` at line 11 column 103 [type=json_invalid, input_value='{\\n  \"positive_points\": ...'s Le Male.\"\\'\"\\n  ]\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: invalid escape at line 9 column 45 [type=json_invalid, input_value='{\\n        \"positive_poi...\\'\"\\n        ]\\n      }', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected `,` or `]` at line 11 column 103 [type=json_invalid, input_value='{\\n  \"positive_points\": ...'s Le Male.\"\\'\"\\n  ]\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: invalid escape at line 9 column 45 [type=json_invalid, input_value='{\\n        \"positive_poi...\\'\"\\n        ]\\n      }', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"positive_...ately wish this set was', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: invalid escape at line 5 column 40 [type=json_invalid, input_value='{\\n        \"positive_poi...\\'\"\\n        ]\\n      }', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"positive_...ately wish this set was', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: invalid escape at line 5 column 40 [type=json_invalid, input_value='{\\n        \"positive_poi...\\'\"\\n        ]\\n      }', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"positive_...ately wish this set was', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: invalid escape at line 5 column 40 [type=json_invalid, input_value='{\\n        \"positive_poi...\\'\"\\n        ]\\n      }', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected `,` or `]` at line 6 column 71 [type=json_invalid, input_value='{\\n  \"positive_points\": ...n packaging.\\'\"\\n  ]\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected `,` or `]` at line 6 column 71 [type=json_invalid, input_value='{\\n  \"positive_points\": ...n packaging.\\'\"\\n  ]\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected `,` or `]` at line 6 column 71 [type=json_invalid, input_value='{\\n  \"positive_points\": ...n packaging.\\'\"\\n  ]\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected `,` or `]` at line 10 column 30 [type=json_invalid, input_value='{\\n      \"positive_point...letely\"\\n      ]\\n    }', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected `,` or `]` at line 10 column 26 [type=json_invalid, input_value='{\\n  \"positive_points\": ...n\\' completely\"\\n  ]\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected `,` or `]` at line 10 column 26 [type=json_invalid, input_value='{\\n  \"positive_points\": ...n\\' completely\"\\n  ]\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected `,` or `]` at line 3 column 27 [type=json_invalid, input_value='{\\n        \"positive_poi...ort\\n        ]\\n      }', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected `,` or `]` at line 3 column 21 [type=json_invalid, input_value='{\\n  \"positive_points\": ...xcessive volume\\n  ]\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected `,` or `]` at line 3 column 21 [type=json_invalid, input_value='{\\n  \"positive_points\": ...xcessive volume\\n  ]\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"positive_...not recommend these for', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n    {\\n      \"p...kin like myself you may', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"positive_...not recommend these for', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n    {\\n      \"p...kin like myself you may', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"positive_...not recommend these for', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n    {\\n      \"p...kin like myself you may', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected `,` or `]` at line 12 column 115 [type=json_invalid, input_value='{\\n      \"positive_point...e cost\"\\n      ]\\n    }', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"positive_...nding/rattling noise\\'\"', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected `,` or `]` at line 12 column 115 [type=json_invalid, input_value='{\\n      \"positive_point...e cost\"\\n      ]\\n    }', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"positive_...nding/rattling noise\\'\"', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected `,` or `]` at line 12 column 115 [type=json_invalid, input_value='{\\n      \"positive_point...e cost\"\\n      ]\\n    }', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"positive_...nding/rattling noise\\'\"', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected `,` or `]` at line 3 column 32 [type=json_invalid, input_value='{\\n      \"positive_point...y scalp\\n      ]\\n    }', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n    {\\n      \"p... really enjoy my. Iâ€™d', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected `,` or `]` at line 3 column 32 [type=json_invalid, input_value='{\\n      \"positive_point...y scalp\\n      ]\\n    }', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"positive_...y enjoy my. Iâ€™d enjoy', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected `,` or `]` at line 3 column 32 [type=json_invalid, input_value='{\\n      \"positive_point...y scalp\\n      ]\\n    }', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"positive_...y enjoy my. Iâ€™d enjoy', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "âš ï¸ Failed to parse for row 1068\n",
            "âš ï¸ Failed to parse for row 1068\n",
            "âš ï¸ Failed to parse for row 1068\n",
            "âš ï¸ Failed to parse for row 1068\n",
            "âš ï¸ Failed to parse for row 1068\n",
            "âš ï¸ Failed to parse for row 1068\n",
            "âš ï¸ Failed to parse for row 1068\n",
            "âš ï¸ Failed to parse for row 1068\n",
            "âš ï¸ Failed to parse for row 1068\n",
            "âš ï¸ Failed to parse for row 1068\n",
            "âš ï¸ Failed to parse for row 1068\n",
            "âš ï¸ Failed to parse for row 1068\n",
            "âš ï¸ Failed to parse for row 1068\n",
            "âš ï¸ Failed to parse for row 1068\n",
            "âš ï¸ Failed to parse for row 1068\n",
            "âš ï¸ Failed to parse for row 1068\n",
            "âš ï¸ Failed to parse for row 1068\n",
            "âš ï¸ Failed to parse for row 1068\n",
            "âš ï¸ Failed to parse for row 1068\n",
            "âš ï¸ Failed to parse for row 1068\n",
            "âš ï¸ Failed to parse for row 1068\n",
            "âš ï¸ Failed to parse for row 1068\n",
            "âœ… Batch 0 done (1049/1071 succeeded).\n",
            "--- Generate hard negative queries: Beauty_and_Personal_Care ---\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... for sensitive skin\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... for sensitive skin\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... for sensitive skin\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... for sensitive skin\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... for sensitive skin\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... for sensitive skin\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... for sensitive skin\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... for sensitive skin\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... for sensitive skin\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...with a natural look\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...with a natural look\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...with a natural look\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...with a natural look\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...with a natural look\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...with a natural look\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...with a natural look\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...with a natural look\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...with a natural look\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... mess like soft wax\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... mess like soft wax\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... mess like soft wax\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... mess like soft wax\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... mess like soft wax\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... mess like soft wax\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... mess like soft wax\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... mess like soft wax\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... mess like soft wax\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... photos and density\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... photos and density\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... photos and density\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... photos and density\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... photos and density\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... photos and density\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... photos and density\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... photos and density\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... photos and density\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...less chemical smell\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...less chemical smell\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...less chemical smell\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...less chemical smell\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...less chemical smell\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...less chemical smell\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...less chemical smell\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...less chemical smell\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...less chemical smell\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...comfortable to wear\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...comfortable to wear\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...comfortable to wear\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...comfortable to wear\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...comfortable to wear\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...comfortable to wear\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...comfortable to wear\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...comfortable to wear\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...comfortable to wear\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... losing the charger\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... losing the charger\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... losing the charger\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...o dry after washing\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...o dry after washing\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...o dry after washing\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...o dry after washing\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...o dry after washing\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...o dry after washing\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...o dry after washing\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...o dry after washing\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...o dry after washing\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...heavy after a while\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...heavy after a while\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...heavy after a while\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...heavy after a while\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...heavy after a while\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...heavy after a while\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...heavy after a while\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...heavy after a while\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...heavy after a while\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... too heavy to apply\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... too heavy to apply\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... too heavy to apply\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... too heavy to apply\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... too heavy to apply\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... too heavy to apply\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... too heavy to apply\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... too heavy to apply\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... too heavy to apply\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...nage for daily wear\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...nage for daily wear\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...nage for daily wear\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...nage for daily wear\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...nage for daily wear\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...nage for daily wear\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...nage for daily wear\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...nage for daily wear\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...nage for daily wear\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...hatâ€™s easy to use\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...hatâ€™s easy to use\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...hatâ€™s easy to use\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... moisturizing cream\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... moisturizing cream\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... moisturizing cream\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... moisturizing cream\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... moisturizing cream\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... moisturizing cream\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... moisturizing cream\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... moisturizing cream\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... moisturizing cream\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...ss wax for coverage\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...ss wax for coverage\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...ss wax for coverage\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...ss wax for coverage\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...ss wax for coverage\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...ss wax for coverage\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...nâ€™t tangle easily\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...nâ€™t tangle easily\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...nâ€™t tangle easily\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...nâ€™t tangle easily\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...nâ€™t tangle easily\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...nâ€™t tangle easily\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...th without tangling\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...th without tangling\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...th without tangling\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...th without tangling\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...th without tangling\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...th without tangling\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...th without tangling\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...th without tangling\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...th without tangling\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...t or getting sticky\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...t or getting sticky\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...t or getting sticky\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...air healthy-looking\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...air healthy-looking\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...air healthy-looking\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...air healthy-looking\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...air healthy-looking\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...air healthy-looking\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...air healthy-looking\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...air healthy-looking\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...air healthy-looking\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...nd no missing parts\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...nd no missing parts\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...nd no missing parts\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...nd no missing parts\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...nd no missing parts\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...nd no missing parts\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...nd no missing parts\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...nd no missing parts\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...nd no missing parts\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...ting after applying\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...ting after applying\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...ting after applying\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...ting after applying\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...ting after applying\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...ting after applying\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...ting after applying\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...ting after applying\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...ting after applying\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...y for long sessions\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...y for long sessions\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...y for long sessions\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...y for long sessions\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...y for long sessions\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...y for long sessions\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...y for long sessions\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...y for long sessions\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...y for long sessions\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...er sections at once\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...er sections at once\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...er sections at once\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...er sections at once\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...er sections at once\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...er sections at once\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...er sections at once\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...er sections at once\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...er sections at once\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...ighter and smoother\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...ighter and smoother\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...ighter and smoother\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...ighter and smoother\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...ighter and smoother\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...ighter and smoother\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...ighter and smoother\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...ighter and smoother\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...ighter and smoother\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...ery small solutions\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...ery small solutions\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...ery small solutions\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...ery small solutions\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...ery small solutions\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...ery small solutions\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...ery small solutions\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...ery small solutions\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...ery small solutions\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... thin after removal\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... thin after removal\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... thin after removal\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... thin after removal\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... thin after removal\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... thin after removal\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... thin after removal\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... thin after removal\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... thin after removal\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...an as the old brush\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...an as the old brush\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...an as the old brush\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...an as the old brush\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...an as the old brush\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...an as the old brush\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... for my medium hair\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... for my medium hair\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"... for my medium hair\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...omes in a good size\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...omes in a good size\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...omes in a good size\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...omes in a good size\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...omes in a good size\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...omes in a good size\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...verlap in the teeth\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...verlap in the teeth\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...verlap in the teeth\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...verlap in the teeth\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...verlap in the teeth\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...verlap in the teeth\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...verlap in the teeth\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...verlap in the teeth\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...verlap in the teeth\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...e bikini and ankles\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...e bikini and ankles\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for HardNegativeQuery\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"query\": \"...e bikini and ankles\"\\n}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "âœ… Batch 0: 3071 hard queries generated.\n",
            "finish pipeline for category: Beauty_and_Personal_Care\n",
            "-- Save files in remote -- \n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c388e8f5af8c4152a3fb637ee2c54aca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce42fa641ac54249a8c1696270a82ac9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "New Data Upload               : |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fee1ffe554744715a00abd100945757d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  ...sonal_Care_part_0.parquet:  41%|####1     |  524kB / 1.26MB            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File saved locally\n",
            "-- save hard negative queries for Beauty_and_Personal_Care --\n",
            "/content/datasets/procesed/review_analysis/Qwen/Qwen2.5-7B-Instruct-GPTQ-Int4/Beauty_and_Personal_Care_review_analysis_part_0.parquet /datasets/procesed/review_analysis/Qwen/Qwen2.5-7B-Instruct-GPTQ-Int4/Beauty_and_Personal_Care_review_analysis_part_0.parquet\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ab0e248ea304d118e04db9514c19c43",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76b69d5524cd4baaabbb9cdc7b8b04d2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "New Data Upload               : |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a06cc0d45cbd407da259941ea53e58b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  ...w_analysis_part_0.parquet:  88%|########8 | 1.05MB / 1.19MB            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File saved locally\n",
            "-- save review analysis for Beauty_and_Personal_Care --\n",
            "Done for Beauty_and_Personal_Care\n",
            "Delete files for /datasets/procesed/hard_negative_queries/Qwen/Qwen2.5-7B-Instruct-GPTQ-Int4\n",
            "Delete files for /datasets/procesed/review_analysis/Qwen/Qwen2.5-7B-Instruct-GPTQ-Int4\n",
            "-- Clear raw ---\n",
            "Load the reviews for category: Clothing_Shoes_and_Jewelry\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "429bbf14e96d41a995f1567ec7f2faa6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ecef27eadf545a0be9282ccdbe6abcd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "raw/review_and_meta_categories/filtered_(â€¦):   0%|          | 0.00/4.85M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Generate positive and negative points for reviews: Clothing_Shoes_and_Jewelry ---\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"positive_...8 normally, so a medium', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "Validation error: 1 validation error for ProductReviewOutline\n",
            "  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"positive_...8 normally, so a medium', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-798216826.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiltered_selected_cats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   res = pipeline_for_generate_hard_queries(\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0midx_category\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3596790768.py\u001b[0m in \u001b[0;36mpipeline_for_generate_hard_queries\u001b[0;34m(idx_category, model, model_name, tokenizer)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"--- Generate positive and negative points for reviews: {idx_category} ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m   \u001b[0mgenerate_positive_and_negative_points_for_reviews\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_final\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx_category\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m   df_all_reviews_cat = [\n",
            "\u001b[0;32m/tmp/ipython-input-4118738195.py\u001b[0m in \u001b[0;36mgenerate_positive_and_negative_points_for_reviews\u001b[0;34m(df_reviews, model, tokenizer, category, model_name, save_local, system_template_path, user_template_path, batch_size)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mchunk_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_messages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             chunk_results = generate_and_parse_batch_with_retry(\n\u001b[0m\u001b[1;32m    101\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4118738195.py\u001b[0m in \u001b[0;36mgenerate_and_parse_batch_with_retry\u001b[0;34m(model, tokenizer, batch_messages, pydantic_model, max_attempts, max_new_tokens, batch_size)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;31m# Generate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             generated_ids = model.generate(\n\u001b[0m\u001b[1;32m    178\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2563\u001b[0m         \u001b[0;31m# 9. Call generation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2564\u001b[0;31m         result = decoding_method(\n\u001b[0m\u001b[1;32m   2565\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2566\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2785\u001b[0m                 \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2786\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2787\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2789\u001b[0m             \u001b[0;31m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;34m\"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         ```\"\"\"\n\u001b[0;32m--> 449\u001b[0;31m         outputs: BaseModelOutputWithPast = self.model(\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moriginal_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m                 \u001b[0;31m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdecoder_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             hidden_states = decoder_layer(\n\u001b[0m\u001b[1;32m    385\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdecoder_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_checkpointing_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;31m# Self Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         hidden_states, _ = self.self_attn(\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_values, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mattention_interface\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mALL_ATTENTION_FUNCTIONS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attn_implementation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         attn_output, attn_weights = attention_interface(\n\u001b[0m\u001b[1;32m    170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mquery_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/integrations/sdpa_attention.py\u001b[0m in \u001b[0;36msdpa_attention_forward\u001b[0;34m(module, query, key, value, attention_mask, dropout, scaling, is_causal, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     attn_output = torch.nn.functional.scaled_dot_product_attention(\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa36cb83",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa36cb83",
        "outputId": "273bae04-966d-410e-cc38-be268fcca0cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Removed 'model' from globals\n",
            "âœ… Removed 'tokenizer' from globals\n",
            "âœ… GPU cache cleared\n",
            "âœ… Cleanup complete - model/tokenizer removed from CPU/GPU\n"
          ]
        }
      ],
      "source": [
        "# # Delete models and tokenizer\n",
        "# import gc\n",
        "# import torch\n",
        "\n",
        "# # Delete global variables\n",
        "# if 'model' in globals():\n",
        "#     del globals()['model']\n",
        "#     print(\"âœ… Removed 'model' from globals\")\n",
        "\n",
        "# if 'tokenizer' in globals():\n",
        "#     del globals()['tokenizer']\n",
        "#     print(\"âœ… Removed 'tokenizer' from globals\")\n",
        "\n",
        "# if 'model_wrapper' in globals():\n",
        "#     del globals()['model_wrapper']\n",
        "#     print(\"âœ… Removed 'model_wrapper' from globals\")\n",
        "\n",
        "# if 'generator' in globals():\n",
        "#     del globals()['generator']\n",
        "#     print(\"âœ… Removed 'generator' from globals\")\n",
        "\n",
        "# # Force garbage collection to free CPU memory\n",
        "# gc.collect()\n",
        "\n",
        "# # Clear GPU cache to free up CUDA memory\n",
        "# if torch.cuda.is_available():\n",
        "#     torch.cuda.empty_cache()\n",
        "#     print(\"âœ… GPU cache cleared\")\n",
        "# else:\n",
        "#     print(\"CUDA not available\")\n",
        "\n",
        "# print(\"âœ… Cleanup complete - model/tokenizer removed from CPU/GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1YJqctee23as"
      },
      "id": "1YJqctee23as",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R2iYQGuP23dm"
      },
      "id": "R2iYQGuP23dm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I8o_JDKZ23gr"
      },
      "id": "I8o_JDKZ23gr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JqUR4IY223jZ"
      },
      "id": "JqUR4IY223jZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_qK6lhVv23mZ"
      },
      "id": "_qK6lhVv23mZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "snnuTglm23pT"
      },
      "id": "snnuTglm23pT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cfZ5-azT23se"
      },
      "id": "cfZ5-azT23se",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9NtEATyp23v4"
      },
      "id": "9NtEATyp23v4",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ccf83d7cd81349a0a946953f9d89430b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48b4f1db4b1843af8775970ab7cb029d",
              "IPY_MODEL_527fec3940764182a35cb760f86ff5eb",
              "IPY_MODEL_3002aa114a7e41c2807f1b0b53bd220e"
            ],
            "layout": "IPY_MODEL_d58ac2d1f0ce4bd888399452f9cd0634"
          }
        },
        "48b4f1db4b1843af8775970ab7cb029d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84d06c21edf44f49aeed72e0cb66cdc4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f84807ef4c014686906a17fab7241329",
            "value": "Fetchingâ€‡1â€‡files:â€‡100%"
          }
        },
        "527fec3940764182a35cb760f86ff5eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0efe8021290141e2a13fd7f9734e2726",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_333e59bb1dcd4c4884e3a7347ceeb65e",
            "value": 1
          }
        },
        "3002aa114a7e41c2807f1b0b53bd220e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3bfeef964ff4932a95e329c697a4a50",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4a403e40ae8b45a1890949e465ed0a3d",
            "value": "â€‡1/1â€‡[00:00&lt;00:00,â€‡116.93it/s]"
          }
        },
        "d58ac2d1f0ce4bd888399452f9cd0634": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84d06c21edf44f49aeed72e0cb66cdc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f84807ef4c014686906a17fab7241329": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0efe8021290141e2a13fd7f9734e2726": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "333e59bb1dcd4c4884e3a7347ceeb65e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3bfeef964ff4932a95e329c697a4a50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a403e40ae8b45a1890949e465ed0a3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}